>  本篇是运输层、TCP、UDP知识点汇总
>
>  参考文献：
>
>  《计算机网络第七版（谢希仁）》
>
>  [40 张图带你搞懂 TCP 和 UDP](https://mp.weixin.qq.com/s/wxzJrSLGDZ6tAt3ys4Vp8g)

# 运输层概述

`运输层`位于应用层和网络层之间，是 OSI 分层体系中的第四层，同时也是网络体系结构的重要部分。运输层主要负责网络上的端到端通信。运输层为运行在不同主机上的应用程序之间的通信起着至关重要的作用。

![image-20201213181254489](img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213181254489.png)

计算机网络的运输层非常类似于高速公路，高速公路负责把人或者物品从一端运送到另一端，而计算机网络的运输层则负责把报文从一端运输到另一端，这个端指的就是 `端系统`。在计算机网络中，任意一个可以交换信息的介质都可以称为端系统，比如手机、网络媒体、电脑、运营商等。

在运输层运输报文的过程中，会遵守一定的协议规范，比如一次传输的数据限制、选择什么样的运输协议等。运输层实现了让两个互不相关的主机进行`逻辑通信`的功能，看起来像是让两个主机相连一样。

运输层协议是在端系统中实现的，而不是在路由器中实现的。路由只是做识别地址并转发的功能。这就比如快递员送快递一样，当然是要由地址的接受人也就是 xxx 号楼 xxx 单元 xxx 室的这个人来判断了！

#### 逻辑通信

运输层提供应用进程间的逻辑通信"。"逻辑通信"的意思是:从应用层来看，只要把应用层报文交给下面的运输层，
运输层就可以把这报文传送到对方的运输层(哪怕双方相距很远，例如几千公里)，好像这种通信就是沿水平方向直接传送数据。但事实上这两个运输层之间并没有一条水平方向的物理连接。数据的传送是沿着图中的虚线方向(经过多个层次)传送的。

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201213204502988.png" alt="image-20201213204502988" style="zoom:50%;" />

从这里可以看出网络层和运输层有明显的区别。网络层为主机之间提供逻辑通信，而运输层为应用进程之间提供端到端的逻辑通信  

运输层向高层用户屏蔽了下面网络核心的细节(如网络拓扑、所采用的路由选择协议等)，它使应用进程看见的就是好像在两个运输层实体之间有一条端到端的逻辑通信信道

但这条逻辑通信信道对上层的表现却因运输层使用的不同协议而有很大的差别。当运输层采用面向连接的 TCP 协议时，尽管下面的网络是不可靠的(只提供尽最大努力服务) ，但这种逻辑通信信道就相当于一条全双工的可靠信道。但当运输层采用无连接的UDP 协议时，这种逻辑通信信道仍然是一条不可靠信道。  

#### 运输层的两个主要协议

TCP/IP 运输层的两个主要协议都是互联网的正式标准，即:

- ==用户数据报协议 UDP==(User Datagram Protocol) [RFC 768]

- ==传输控制协议 TCP== (Transmission Control Protocol) [RFC 793]  

下图给出了这两种协议在协议栈中的位置：

<img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201213205305469.png" alt="image-20201213205305469" style="zoom: 67%;" />

按照 OSI 的术语，两个对等运输实体在通信时传送的数据单位叫做运输协议数据单元TPDU (Transport Protocol Data Unit)。但在 TCPIIP 体系中，则根据所使用的协议是 TCP 或UDP ，分别称之为 ==TCP 报文段==(segment) 或==UDP 用户数据报==。  

**TCP 则提供可靠的面向连接的服务**。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP 要提供可靠的、面向连接的运输服务，因此不可避免地增加了许多的开销，如确认、流量控制、计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多的处理机资源。  

**UDP 在传送数据之前不需要先建立连接**。远地主机的运输层在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 却是一种最有效的工作方式。  

一些应用和应用层协议主要使用的运输层协议如下表：

<img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201213205758382.png" alt="image-20201213205758382" style="zoom:70%;" /> 

#### 复用和分用

复用：是指在发送方不同的应用进程都可以使用同一个运输层协议传送数据(当然需要加上适当的
首部)，即应用层所有的应用进程都可以通过运输层再传送到IP层(网络层)  

分用：是指接收方的运输层在剥去报文的首部后能够把这些数据正确交付目的应用进程 ，即运输层从 IP 层收到发送给各应用进程的数据后，必须分别交付指明的各应用进程  

# TCP 和 UDP 前置知识

在 TCP/IP 协议中能够实现传输层功能的，最具代表性的就是 TCP 和 UDP。提起 TCP 和 UDP ，就得先从这两个协议的定义说起。

TCP 叫做`传输控制协议(TCP，Transmission Control Protocol)`，通过名称可以大致知道 TCP 协议有控制传输的功能，主要体现在其可控，可控就表示着可靠，确实是这样的，TCP 为应用层提供了一种**可靠的、面向连接**的服务，它能够将分组可靠的传输到服务端。

UDP 叫做 `用户数据报协议(UDP，User Datagram Protocol)`，通过名称可以知道 UDP 把重点放在了数据报上，它为应用层提供了一种无需建立连接就可以直接发送数据报的方法。

### 套接字

在 TCP 或者 UDP 发送具体的报文信息前，需要先经过一扇 `门`，这个门就是`套接字(socket)`，套接字向上连接着应用层，向下连接着网络层。在操作系统中，操作系统分别为应用和硬件提供了`接口(Application Programming Interface)`。而在计算机网络中，套接字同样是一种接口，它也是有接口 API 的。

使用 TCP 或 UDP 通信时，会广泛用到套接字的 API，使用这套 API 设置 IP 地址、端口号，实现数据的发送和接收。

<img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213182030399.png" alt="image-20201213182030399" style="zoom:50%;" />

现在我们知道了， Socket 和 TCP/IP 没有必然联系，Socket 的出现只是方便了 TCP/IP 的使用，如何方便使用呢？你可以直接使用下面 Socket API 的这些方法。

<img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213182101153.png" alt="image-20201213182101153" style="zoom:50%;" />

#### 套接字类型

套接字的主要类型有三种

- `数据报套接字(Datagram sockets)`：数据报套接字提供一种`无连接`的服务，而且并不能保证数据传输的可靠性。数据有可能在传输过程中丢失或出现数据重复，且无法保证顺序地接收到数据。数据报套接字使用`UDP( User DatagramProtocol)协议`进行数据的传输。由于数据报套接字不能保证数据传输的可靠性，对于有可能出现的数据丢失情况，需要在程序中做相应的处理。
- `流套接字(Stream sockets)`: 流套接字用于提供面向连接、可靠的数据传输服务。能够保证数据的可靠性、顺序性。流套接字之所以能够实现可靠的数据服务，原因在于其使用了传输控制协议，即 `TCP(The Transmission Control Protocol)协议`
- `原始套接字(Raw sockets)`: 原始套接字允许直接发送和接收 IP 数据包，而无需任何特定于协议的传输层格式，原始套接字可以读写内核没有处理过的 IP 数据包。

#### 套接字处理过程

在计算机网络中，要想实现通信，必须至少需要两个端系统，至少需要一对两个套接字才行。下面是套接字的通信过程。

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213182358274.png" alt="image-20201213182358274" style="zoom:50%;" />

1. socket 中的 API 用于创建通信链路中的端点，创建完成后，会返回描述该套接字的`套接字描述符`。就像使用文件描述符来访问文件一样，套接字描述符用来访问套接字。
2. 当应用程序具有套接字描述符后，它可以将唯一的名称绑定在套接字上，服务器必须绑定一个名称才能在网络中访问
3. 在为服务端分配了 socket 并且将名称使用 bind 绑定到套接字上后，将会调用 listen api。`listen` 表示客户端愿意等待连接的意愿，listen 必须在 accept api 之前调用。
4. 客户端应用程序在流套接字(基于 TCP)上调用 `connect` 发起与服务器的连接请求。
5. 服务器应用程序使用`accept`API 接受客户端连接请求，服务器必须先成功调用 bind 和 listen 后，再调用 accept api。
6. 在流套接字之间建立连接后，客户端和服务器就可以发起 read/write api 调用了。
7. 当服务器或客户端要停止操作时，就会调用 `close` API 释放套接字获取的所有系统资源。

虽然套接字 API 位于应用程序层和传输层之间的通信模型中，但是套接字 API 不属于通信模型。套接字 API 允许应用程序与传输层和网络层进行交互。

在往下继续聊之前，我们先播放一个小插曲，简单聊一聊 IP。

### IP

`IP` 是`Internet Protocol（网际互连协议）`的缩写，是 TCP/IP 体系中的`网络层`协议。设计 IP 的初衷主要想解决两类问题

- 提高网络扩展性：实现大规模网络互联
- 对应用层和链路层进行解藕，让二者独立发展。

IP 是整个 TCP/IP 协议族的核心，也是构成互联网的基础。为了实现大规模网络的互通互联，IP 更加注重适应性、简洁性和可操作性，并在可靠性做了一定的牺牲。IP 不保证分组的**交付时限和可靠性**，所传送分组有可能出现**丢失、重复、延迟或乱序**等问题。

> 我们知道，TCP 协议的下一层就是 IP 协议层，既然 IP 不可靠，那么如何保证数据能够准确无误地到达呢？

这就涉及到 TCP 传输机制的问题了，我们后面聊到 TCP 的时候再说。

### 端口号

在聊端口号前，先来聊一聊文件描述以及 socket 和端口号的关系

> 为了方便资源的使用，提高机器的性能、利用率和稳定性等等原因，我们的计算机都有一层软件叫做操作系统，它用于帮我们管理计算机可以使用的资源，当我们的程序要使用一个资源的时候，可以向操作系统申请，再由操作系统为我们的程序分配和管理资源。通常当我们要访问一个内核设备或文件时，程序可以调用系统函数，系统就会为我们打开设备或文件，然后返回一个文件描述符fd（或称为ID，是一个整数），我们要访问该设备或文件，只能通过该文件描述符。可以认为该编号对应着打开的文件或设备。

而当我们的程序要使用网络时，要使用到对应的操作系统内核的操作和网卡设备，所以我们可以向操作系统申请，然后系统会为我们创建一个套接字 Socket，并返回这个 Socket 的ID，以后我们的程序要使用网络资源，只要向这个 Socket 的编号 ID 操作即可。而我们的每一个网络通信的进程至少对应着一个 Socket。向 Socket 的 ID 中写数据，相当于向网络发送数据，向 Socket 中读数据，相当于接收数据。而且这些套接字都有唯一标识符——文件描述符 fd。

端口号是 `16` 位的非负整数，它的范围是 0 - 65535 之间，这个范围会分为三种不同的端口号段，由 Internet 号码分配机构 IANA 进行分配

- 周知/标准端口号，它的范围是 0 - 1023
- 注册端口号，范围是 1024 - 49151
- 私有端口号，范围是 49152 - 6553

一台计算机上可以运行多个应用程序，当一个报文段到达主机后，应该传输给哪个应用程序呢？你怎么知道这个报文段就是传递给 HTTP 服务器而不是 SSH 服务器的呢？

是凭借端口号吗？当报文到达服务器时，是端口号来区分不同应用程序的，所以应该借助端口号来区分。

举个例子反驳一下，假如到达服务器的两条数据都是由 80 端口发出的你该如何区分呢？或者说到达服务器的两条数据端口一样，协议不同，该如何区分呢？

所以仅凭端口号来确定某一条报文显然是不够的。

互联网上一般使用 **源 IP 地址、目标 IP 地址、源端口号、目标端口号** 来进行区分。如果其中的某一项不同，就被认为是不同的报文段。这些也是`多路分解和多路复用` 的基础。

#### 确定端口号

在实际通信之前，需要先确定一下端口号，确定端口号的方法分为两种：

- 标准既定的端口号

标准既定的端口号是静态分配的，每个程序都会有自己的端口号，每个端口号都有不同的用途。端口号是一个 16 比特的数，其大小在 0 - 65535 之间，0 - 1023 范围内的端口号都是动态分配的既定端口号，例如 HTTP 使用 80 端口来标识，FTP 使用 21 端口来标识，SSH 使用 22 来标识。这类端口号有一个特殊的名字，叫做 `周知端口号(Well-Known Port Number)`。

- 时序分配的端口号

第二种分配端口号的方式是一种动态分配法，在这种方法下，客户端应用程序可以完全不用自己设置端口号，凭借操作系统进行分配，操作系统可以为每个应用程序分配互不冲突的端口号。这种动态分配端口号的机制即使是同一个客户端发起的 TCP 连接，也能识别不同的连接。

### 多路复用和多路分解

我们上面聊到了在主机上的每个套接字都会分配一个端口号，当报文段到达主机时，运输层会检查报文段中的目的端口号，并将其定向到相应的套接字，然后报文段中的数据通过套接字进入其所连接的进程。下面我们来聊一下什么是多路复用和多路分解的概念。

多路复用和多路分解分为两种，即`无连接`的多路复用(多路分解)和`面向连接`的多路复用(多路分解)

#### 无连接的多路复用和多路分解

开发人员会编写代码确定端口号是周知端口号还是时序分配的端口号。假如主机 A 中的一个 10637 端口要向主机 B 中的 45438 端口发送数据，运输层采用的是 `UDP` 协议，数据在应用层产生后，会在运输层中加工处理，然后在网络层将数据封装得到 IP 数据报，IP 数据包通过链路层尽力而为的交付给主机 B，然后主机 B 会检查报文段中的端口号判断是哪个套接字的，这一系列的过程如下所示

<img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213182956597.png" alt="image-20201213182956597" style="zoom:67%;" />

UDP 套接字就是一个二元组，二元组包含目的 IP 地址和目的端口号。

所以，如果两个 UDP 报文段有不同的源 IP 地址和/或相同的源端口号，但是具有相同的目的 IP 地址和目的端口号，那么这两个报文会通过套接字定位到相同的目的进程。

这里思考一个问题，主机 A 给主机 B 发送一个消息，为什么还需要知道源端口号呢？比如我给妹子表达出我对你有点意思的信息，妹子还需要知道这个信息是从我的哪个器官发出的吗？知道是我这个人对你有点意思不就完了？实际上是需要的，因为妹子如果要表达出她对你也有点意思，她是不是可能会亲你一口，那她得知道往哪亲吧？

这就是，在 A 到 B 的报文段中，源端口号会作为 `返回地址` 的一部分，即当 B 需要回发一个报文段给 A 时，B 需要从 A 到 B 中的源端口号取值，如下图所示

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213183031746.png" alt="image-20201213183031746" style="zoom:50%;" />

#### 面向连接的多路复用多路分解

如果说无连接的多路复用和多路分解指的是 UDP 的话，那么面向连接的多路复用与多路分解指的是 TCP 了，TCP 和 UDP 在报文结构上的差别是，UDP 是一个二元组而 TCP 是一个四元组，即**源 IP 地址、目标 IP 地址、源端口号、目标端口号** ，这个我们上面也提到了。当一个 TCP 报文段从网络到达一台主机时，这个主机会根据这四个值拆解到对应的套接字上。

<img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213183130904.png" alt="image-20201213183130904" style="zoom:67%;" />

上图显示了面向连接的多路复用和多路分解的过程，图中主机 C 向主机 B 发起了两个 HTTP 请求，主机 A 向主机 C 发起了一个 HTTP 请求，主机 A、B、C 都有自己唯一的 IP 地址，当主机 C 发出 HTTP 请求后，主机 B 能够分解这两个 HTTP 连接，因为主机 C 发出请求的两个源端口号不同，所以对于主机 B 来说，这是两条请求，主机 B 能够进行分解。对于主机 A 和主机 C 来说，这两个主机有不同的 IP 地址，所以对于主机 B 来说，也能够进行分解。

# UDP

UDP 的全称是 `用户数据报协议(UDP，User Datagram Protocol)`，UDP 为应用程序提供了一种`无需建立连接`就可以发送封装的 IP 数据包的方法。如果应用程序开发人员选择的是 UDP 而不是 TCP 的话，那么该应用程序相当于就是和 IP 直接打交道的。用户数据报协议 UDP 只在 IP 的数据报服务之上增加了很少一点的功能，这就是复用和
分用的功能以及差错检测的功能。  

从应用程序传递过来的数据，会附加上多路复用/多路分解的源和目的端口号字段，以及其他字段，然后将形成的报文传递给网络层，网络层将运输层报文段封装到 IP 数据报中，然后尽力而为的交付给目标主机。最关键的一点就是，使用 UDP 协议在将数据报传递给目标主机时，发送方和接收方的运输层实体间是没有`握手`的。正因为如此，UDP 被称为是`无连接`的协议。

### UDP 特点

UDP 协议一般作为流媒体应用、语音交流、视频会议所使用的传输层协议，我们大家都知道的 DNS 协议底层也使用了 UDP 协议，这些应用或协议之所以选择 UDP 主要是因为以下这几点：**<font color='red'>无连接、不可靠、数据报服务</font>**

- ==速度快==，采用 UDP 协议时，只要应用进程将数据传给 UDP，UDP 就会将此数据打包进 UDP 报文段并立刻传递给网络层，然后 TCP 有拥塞控制的功能，它会在发送前判断互联网的拥堵情况，如果互联网极度阻塞，那么就会抑制 TCP 的发送方。使用 UDP 的目的就是希望实时性。
- ==无须建立连接==，TCP 在数据传输之前需要经过三次握手的操作，而 UDP 则无须任何准备即可进行数据传输。即发送数据之前不需要建立连接(当然，发送数据结束时也没有连接可释放)，因此减少了开销和发送数据之前的时延。  
- ==无连接状态==，TCP 需要在端系统中维护`连接状态`，连接状态包括接收和发送缓存、拥塞控制参数以及序号和确认号的参数，在 UDP 中没有这些参数，也没有发送缓存和接受缓存。因此，某些专门用于某种特定应用的服务器当应用程序运行在 UDP 上，一般能支持更多的活跃用户
- ==分组首部开销小==，每个 TCP 报文段都有 20 字节的首部开销，而 UDP 仅仅只有 8 字节的开销。
- ==UDP 使用尽最大努力交付==，即不保证可靠交付，因此主机不需要维持复杂的连接状态表(这里面有许多参数)。  
- ==UDP 是面向报文的==。发送方的 UDP 对应用程序交下来的报文，在添加首部后就向下交付 IP 层。 UDP 对应用层交下来的报文，既不合井，也不拆分，而是保留这些报文的边界  。因此，应用程序必须选择合适大小的报文。若报文太长， UDP 把它交给 IP 层后， IP 层在传送时可能要进行分片，这会降低 IP 层的效率。反之，若报文太短， UDP 把它交给 IP 层后，会使 IP 数据报的首部的相对长度太大，这也降低了 IP 层的效率。  
- ==UDP 没有拥塞控制==，因此网络出现的拥塞不会使源主机的发送速率降低。这对某些实时应用是很重要的。很多的实时应用(如 IP 电话、实时视频会议等)要求源主机以恒定的速率发送数据，并且允许在网络发生拥塞时丢失一些数据，但却不允许数据有太大的时延。 UDP 正好适合这种要求。  
- ==UDP 支持一对一、一对多、多对一和多对多的交互通信==。  

这里需要注意一点，并不是所有使用 UDP 协议的应用层都是`不可靠`的，应用程序可以自己实现可靠的数据传输，通过增加确认和重传机制。所以使用 UDP 协议最大的特点就是速度快。

### UDP 报文结构

下面来一起看一下 UDP 的报文结构，每个 UDP 报文分为 UDP 报头和 UDP 数据区两部分。报头只有8个字节，由四个字段组成，每个字段的长度都是两个字节。分别说明该报文的源端口、目的端口、报文长度和校验值。如下图：

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201213212238982.png" alt="image-20201213212238982" style="zoom:67%;" />

- ==源端口号(Source Port)== :这个字段占据 UDP 报文头的前 16 位，通常包含发送数据报的应用程序所使用的 UDP 端口。接收端的应用程序利用这个字段的值作为发送响应的目的地址。在需要对方回信时使用，不需要时可用全0
- ==目标端口号(Destination Port)==: 表示接收端端口，在终点交付报文时必须使用，字段长为 16 位
- ==长度(Length)==:  UDP用户数据报长度，包含 UDP 报文头加UDP 数据的总长度。因为 UDP 报文头长度是 8 个字节，所以这个值最小为 8，最大长度为 65535 字节。
- ==校验和(Checksum)==：UDP 使用校验和来保证数据安全性，UDP 的校验和也提供了差错检测功能，差错检测用于校验报文段从源到目标主机的过程中，数据的完整性是否发生了改变。有错就丢弃

当运输层从 IP 层收到 UDP 数据报时，就根据首部中的目的端口，把 UDP 数据报通过相应的端口，上交最后的终点一一应用进程。下图是 UDP 基于端口分用的示意图。  

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201213212727909.png" alt="image-20201213212727909" style="zoom:67%;" />

**注意**，虽然在 UDP 之间的通信要用到其端口号，但由于 UDP 的通信是无连接的，因此不需要使用套接宇 CTCP 之间的通信必须要在两个套接字之间建立连接)。  

**伪首部**：UDP 用户数据报首部中检验和的计算方法有些特殊。在计算检验和时，要在 UDP 用户数据报之前增加 12 个字节的伪首部。所谓"伪首部"是因为这种伪首部并不是 UDP 用户数据报真正的首部。只是在计算检验和时，临时添加在 UDP 用户数据报前面，得到一个临时的UDP 用户数据报。检验和就是按照这个临时的 UDP 用户数据报来计算的。伪首部既不向下传送也不向上递交，而仅仅是为了计算检验和。最上面的图给出了伪首部各字段的内容。  

**检验和**：UDP 计算检验和的方法和计算 IP 数据报首部检验和的方法相似。但不同的是: IP 数据报的检验和只检验 IP 数据报的首部，但 UDP 的检验和是把首部和数据部分一起都检验。

在发送方，首先是先把全零放入检验和字段。

再把伪首部以及 UDP 用户数据报看成是由许多16 位的字串接起来的。若 UDP 用户数据报的数据部分不是偶数个字节，则要填入一个全零字节(但此字节不发送)。

然后按二进制反码计算出这些 16 位字的和。将此和的二进制反码写入检验和字段后，就发送这样的 UDP 用户数据报。在接收方，把收到的 UDP 用户数据报连同伪首部(以及可能的填充全零字节)一起，按二进制反码求这些 16 位字的和。当无差错时其结果应为全 1 。否则就表明有差错出现，接收方就应丢弃这个 UDP 用户数据报(也可以上交给应用层，但附上出现了差错的警告)。  

> 下面来想一个问题，为什么 UDP 会提供差错检测的功能？
>
> 这其实是一种 `端到端` 的设计原则，这个原则说的是**要让传输中各种错误发生的概率降低到一个可以接受的水平**。
>
> 文件从主机A传到主机B，也就是说AB主机要通信，需要经过三个环节：首先是主机A从磁盘上读取文件并将数据分组成一个个数据包packet,，然后数据包通过连接主机A和主机B的网络传输到主机B，最后是主机B收到数据包并将数据包写入磁盘。在这个看似简单其实很复杂的过程中可能会由于某些原因而影响正常通信。比如：磁盘上文件读写错误、缓冲溢出、内存出错、网络拥挤等等这些因素都有可能导致数据包的出错或者丢失，由此可见用于通信的网络是不可靠的。
>
> 由于实现通信只要经过上述三个环节，那么我们就想是否在其中某个环节上增加一个检错纠错机制来用于对信息进行把关呢？
>
> 网络层肯定不能做这件事，因为网络层的最主要目的是增大数据传输的速率，网络层不需要考虑数据的完整性，数据的完整性和正确性交给端系统去检测就行了，因此在数据传输中，对于网络层只能要求其提供尽可能好的数据传输服务，而不可能寄希望于网络层提供数据完整性的服务。
>
>UDP 不可靠的原因是它虽然提供差错检测的功能，但是**对于差错没有恢复能力更不会有重传机制**。

# TCP

UDP 是一种没有复杂的控制，提供无连接通信服务的一种协议，换句话说，它将部分控制部分交给应用程序去处理，自己只提供作为传输层协议最基本的功能。

而与 UDP 不同的是，同样作为传输层协议，TCP 协议要比 UDP 的功能多很多。

`TCP` 的全称是 `Transmission Control Protocol`，它被称为是一种`面向连接(connection-oriented)` 的协议，这是因为一个应用程序开始向另一个应用程序发送数据之前，这两个进程必须先进行`握手`，握手是一个逻辑连接，并不是两个主机之间进行真实的握手。

这个连接是指各种设备、线路或者网络中进行通信的两个应用程序为了相互传递消息而专有的、虚拟的通信链路，也叫做虚拟电路。

一旦主机 A 和主机 B 建立了连接，那么进行通信的应用程序只使用这个虚拟的通信线路发送和接收数据就可以保证数据的传输，TCP 协议负责控制连接的建立、断开、保持等工作。

### TCP特点

**<font color='red'>面向连接、可靠、字节流服务</font>**

- ==TCP 是面向连接的运输层协议==。这就是说，应用程序在使用 TCP 协议之前，必须先建立 TCP 连接。在传送数据完毕后，必须释放已经建立的 TCP 连接。也就是说，应用进程之间的通信好像在"打电话"通话前要先拨号建立连接，通话结束后要挂机释放连接。

- ==每一条 TCP 连接只能有两个端点 (endpoint)== ，每一条 TCP 连接只能是点对点的(一对一) ，即只能进行 `点对点(point-to-point)` 连接，那么所谓的`多播`，即一个主机对多个接收方发送消息的情况是不存在的，TCP 连接只能连接两个一对主机。如下图：

   <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213184311178.png" alt="image-20201213184311178" style="zoom:40%;" />

- ==TCP 提供可靠交付的服务==。通过 TCP 连接传送的数据，无差错、不丢失、不重复，
  并且按序到达。  

- ==TCP 提供全双工通信==。 TCP 允许通信双方的应用进程在任何时候都能发送数据。TCP 连接的两端都设有**发送缓存和接收缓存**，用来临时存放双向通信的数据。在发送时，应用程序在把数据传送给 TCP 的缓存后，就可以做自己的事，而 TCP 在合适的时候把数据发送出去。在接收时， TCP 把收到的数据放入缓存，上层的应用进程在合适的时候读取缓存中的数据。  

- ==面向字节流==。 TCP 中的"流" (stream)指的是流入到进程或从进程流出的字节序列。"面向字节流"的含义是:虽然应用程序和 TCP 的交互是一次一个数据块(大小不等)，但TCP 把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。 TCP 并不知道所传送的字节流的含义。 TCP 不保证接收方应用程序所收到的数据块和发送方应用程序所发出的数据块具有对应大小的关系。但接收方应用程序收到的字节流必须和发送方应用程序发出的字节流完全一样。当然，接收方的应用程序必须有能力识别收到的宇节流，把它还原成有意义的应用层数据  

  示意图如下：

   <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201213220415418.png" alt="image-20201213220415418" style="zoom:50%;" />

  > TCP 和 UDP 在发送报文时所采用的方式完全不同。 TCP 并不关心应用进程一次把多长的报文发送到 TCP 的缓存中，而是根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少个字节 (UDP 发送的报文长度是应用进程给出的)。如果应用进程传送到 TCP 缓存的数据块太长， TCP 就可以把它划分短一些再传送。如果应用进程一次只发来一个字节， TCP 也可以等待积累有足够多的宇节后再构成报文段发送出去。
  > 关于 TCP 报文段的长度问题，在后面还要进行讨论  

### TCP连接前置知识

每一条 TCP 连接有两个端点。那么， TCP 连接的端点是什么呢?不是主机，不是主机的 IP 地址，不是应用进程，也不是运输层的协议端口。 TCP 连接的端点叫做套接字(socket)或插口。根据RFC 793 的定义：端口号拼接到(concatenated with) IP 地址即构成了套接字。

因此，套接字的表示方法是在点分十进制的 E 地址后面写上端口号，中间用冒号或逗号隔开。例如，若 IP 地址是 192.3 .4.5 而端口号是 80，那么得到的套接字就是(192.3.4.5: 80)。总之，我们有：

==套接字 socket = (IP 地址:端口号)==

每一条 TCP 连接唯-地被通信两端的两个端点(即两个套接字)所确定。 即:

 ==TCP 连接::= {socket1, socket2} = {(IP1: portl), (IP2: port2)}== 

这里 IPl 和 IP2 分别是两个端点主机的 E 地址，而 POrtl 和 POrt2 分别是两个端点主机中的端口号。 TCP 连接的两个套接字就是 socket1 和 socket2

> 注意：socket的多重意思
>
> 随着互联网的不断发展，以及网络技术的进步，同一个名词 socket 却可表示多种不同的意思。例如:  
>
> (1) 允许应用程序访问连网协议的应用编程接口 API (Application Programming Interface)，即运输层和应用层之间的一种接口，称为 socketAPI，并简称为 socket。  
>
> (2) 在 socketAPI 中使用的一个函数名也叫做 socket
>
> (3) 调用 socket 函数的端点称为 socket ，如"创建一个数据报 socket" 。  
>
> (4) 调用 socket 函数时，其返回值称为 socket 描述符，可简称为 socket 。  
>
> (5) 在操作系统内核中连网协议的 Berkeley 实现，称为 socket 实现。  
>
> 上面的这些 socket 的意思都和本章所引用的 RFC 793 定义的 socket (指端口号拼接到IP地址)不同。注意!!!  

TCP 的连接建立需要经过三次握手，这个我们下面再说。一旦 TCP 连接建立后，主机之间就可以相互发送数据了，客户进程通过套接字传送数据流。数据一旦通过套接字后，它就由客户中运行的 TCP 协议所控制。

TCP 会将数据临时存储到连接的`发送缓存(send buffer)` 中，这个 send buffer 是三次握手之间设置的缓存之一，然后 TCP 在合适的时间将发送缓存中的数据发送到目标主机的接收缓存中，实际上，每一端都会有发送缓存和接收缓存，如下所示

<img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213184355578.png" alt="image-20201213184355578" style="zoom:67%;" />

主机之间的发送是以 `报文段(segment)` 进行的，那么什么是 Segement 呢？

TCP 会将要传输的数据流分为多个`块(chunk)`，然后向每个 chunk 中添加 TCP 标头，这样就形成了一个 TCP 段也就是报文段。每一个报文段可以传输的长度是有限的，不能超过`最大数据长度(Maximum Segment Size)`，俗称 `MSS`。在报文段向下传输的过程中，会经过链路层，链路层有一个 `Maximum Transmission Unit` ，最大传输单元 MTU， 即数据链路层上所能通过最大数据包的大小，最大传输单元通常与通信接口有关。

> 那么 MSS 和 MTU 有啥关系呢？

因为计算机网络是分层考虑的，这个很重要，不同层的称呼不一样，对于传输层来说，称为报文段而对网络层来说就叫做 IP 数据包，所以，**MTU 可以认为是网络层能够传输的最大 IP 数据包，而 MSS（Maximum segment size）可以认为是传输层的概念，也就是 TCP 数据包每次能够传输的最大量**。

### 可靠传输的工作原理

TCP 发送的报文段是交给四层传送的。但 IP 层只能提供尽最大努力服务，  也就是说， TCP 下面的网络所提供的是不可靠的传输。因此， TCP 必须采用适当的措施才能使得两个运输层之间的通信变得可靠。  

理想的传输条件有以下两个特点:

(1) 传输信道不产生差错。

(2) 不管发送方以多快的速度发送数据，接收方总是来得及处理收到的数据。

在这样的理想传输条件下，不需要采取任何措施就能够实现可靠传输。然而实际的网络都不具备以上两个理想条件。但我们可以使用一些可靠传输协议，==当出现差错时让发送方重传出现差错的数据，同时在接收方来不及处理收到的数据时，及时告诉发送方适当降低发送数据的速度==。这样一来，本来不可靠的传输信道就能够实现可靠传输
了。下面从最简单的停止等待协议讲起。  

#### 停止等待协议  

"停止等待"就是每发送完一个分组就停止发送，等待对方的确认。在收到确认后再发送下一个分组。  

停止等待协议可用如下图来说明。下图是最简单的无差错情况。 A 发送分组 Ml，发完就暂停发送，等待 B 的确认。 B 收到了 M1 就向 A 发送确认。 A 在收到了对 M1 的确认后，就再发送下一个分组 M2。同样，在收到 B 对 M2 的确认后，再发送 M3

![image-20201213231932830](img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201213231932830.png)

上图右边是分组在传输过程中出现差错的情况。  B 接收 M1 时检测出了差错，就丢弃Ml，其他什么也不做(不通知 A 收到有差错的分组)。也可能是 M1 在传输过程中丢失了，这时 B 当然什么都不知道。在这两种情况下 ， B 都不会发送任何信息。

可靠传输协议是这样设计的 :A 只要超过了一段时间仍然没有收到确认，就认为刚才发送的分组丢失了，因而重传前面发送过的分组。这就叫做==超时重传==。要实现超时重传，就要在每发送完一个分组时设置一个超时计时器。如果在超时计时器到期之前收到了对方的确认，就撤销己设置的超时计时器。其实在图右中， A 为每一个己发送的分组都设置了一个超时计时器。但 A只要在超时计时器到期之前收到了相应的确认，就撤销该超时计时器。  

这里应注意以下三点。 

- A 在发送完一个分组后，必须暂时保留已发送的分组的副本(在发生超时重传时使用)。只有在收到相应的确认后才能清除暂时保留的分组副本。  
- 分组和确认分组都必须进行编号。这样才能明确是哪一个发送出去的分组收到了确认，而哪一个分组还没有收到确认。  
- 超时计时器设置的重传时间应当比数据在分组传输的平均往返时间更长-些。  

**确认丢失和确认迟到**  

下图说明的是另一种情况。 B 所发送的对 M1 的==确认丢失==了。 A 在设定的超时重传时间内没有收到确认，并无法知道是自己发送的分组出错、丢失，或者是 B 发送的确认丢失了。因此 A 在超时计时器到期后就要重传 M10 现在应注意 B 的动作。假定 B 又收到了重传的分组 M1 。这时应采取两个行动

1. 丢弃这个重复的分组 Ml不向上层交付。  

2. 向 A 发送确认。不能认为己经发送过确认就不再发送，因为 A 之所以重传 M1  就表示 A 没有收到对 M1 的确认。  

   ![image-20201213233155394](img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201213233155394.png)

上图右)也是一种可能出现的情况。传输过程中没有出现差错，但B对分组M1的==确认迟到==了。A会收到重复的确认，对重复的确认直接丢弃掉。B 仍然会收到重复的 M1 ， 并且同样要丢弃重复的 M1 • 并重传确认分组。

通常 A 最终总是可以收到对所有发出的分组的确认。如果 A 不断重传分组但总是收不到确认，就说明通信线路太差，不能进行通信。

使用上述的确认和重传机制，我们就可以在不可靠的传输网络上实现可靠的通信。

像上述的这种可靠传输协议常称为==自动重传请求 ARQ== (Automatic Repeat reQuest)。意思是重传的请求是自动进行的。接收方不需要请求发送方重传某个出错的分组。  

**信道利用率**

停止等待协议的优点是简单，但缺点是信道利用率太低  ，如下图：

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201214105714245.png" alt="image-20201214105714245" style="zoom:67%;" />

TD：发送分组需要的时间

RTT：往返时间

TA：B发送确认分组的时间

因为仅仅是在时间TD内才用来传送有用的数据(包括分组的首部).因此信道的利用率 U 可用下式计算:  

信道利用率：U = TD/(TD+RTT+TA)

往返时间 RTT 远大于分组发送时间TD时，信道的利用率就会非常低。还应注意的是，上图并没有考虑出现差错后的分组重传。若出现重传，则对传送有用的数据信息来说，信道的利用率就还要降低。

为了提高传输效率，发送方可以不使用低效率的停止等待协议，而是采用流水线传输(如下图所示)。流水线传输就是发送方可连续发送多个分组，不必每发完一个分组就停顿下来等待对方的确认。这样可使信道上一直有数据不间断地在传送。显然，这种传输方式可以获得很高的信道利用率。  

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201214110234372.png" alt="image-20201214110234372" style="zoom:50%;" />

当使用流水线传输时，就要使用下面介绍的连续 ARQ 协议和滑动窗口协议。 

#### 连续ARQ协议

ARQ：Automatic Repeat reQuest 自动重传请求

由于停止等待ARQ协议信道利用率太低，所以需要使用连续ARQ协议来进行改善。这个协议会连续发送一组数据包，然后再等待这些数据包的ACK。

发送方采用流水线传输。流水线传输就是发送方可以连续发送多个分组，不必每发完一个分组就停下来等待对方确认。如上图（5-12）所示

==连续ARQ协议通常是结合滑动窗口协议来使用的==，发送方需要维持一个发送窗口，如下图所示：

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201214111055685.png" alt="image-20201214111055685" style="zoom:60%;" />

连续 ARQ 协议规定，发送方每收到一个确认，就把发送窗口向前滑动一个分组的位置

接收方一般都是采用累积确认的方式。这就是说，接收方不必对收到的分组逐个发送确认，而是在收到几个分组后，对按序到达的最后一个分组发送确认，这就表示:到这个分组为止的所有分组都己正确收到了。  

累积确认有优点也有缺点。优点是:容易实现，即使确认丢失也不必重传。但缺点是不能向发送方反映出接收方已经正确收到的所有分组的信息。  

例如，如果发送方发送了前 5 个分组，而中间的第 3 个分组丢失了。这时接收方只能对前两个分组发出确认。发送方无法知道后面三个分组的下落，而只好把后面的三个分组都再重传一次。这就叫做 ==Go-back-N== (回退 N) ，表示需要再退回来重传己发送过的 N 个分组。可见当通信线路质量不好时，连续 ARQ 协议会带来负面的影响。
在深入讨论 TCP 的可靠传输问题之前，必须先了解 TCP 的报文段首部的格式。  

### TCP 报文段结构

TCP 虽然是面向字节流的，但 TCP 传送的数据单元却是报文段。一个 TCP 报文段分为首部和数据两部分，而 TCP 的全部功能都体现在它首部中各字段的作用。因此，只有弄清TCP 首部各字段的作用才能掌握 TCP 的工作原理。下面讨论 TCP 报文段的首部格式

TCP报文段首部的前20个字节是固定的，后面有4n字节是根据需要而增加的选项（n是整数）。因此TCP首部的最小长度是20字节，TCP报文段结构如下图所示

<img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201214184052026.png" alt="image-20201214184052026" style="zoom:67%;" />

首部固定部分各宇段的意义如下:  

- ==源端口和目的端口==：各占 2 个字节，分别写入源端口号和目的端口号。和前面的 UDP 的分用相似， TCP 的分用功能也是通过端口实现的。  

- ==序号==：占四字节。序号范围是 [0， 2^32-1] ，共 2^32 (即 4 294 967296) 个序号。序号增加到 2^32-1 后，下一个序号就又回到 0。也就是说，序号使用 mod 2^32 运算。 **TCP 是面向字节流的。在一个 TCP 连接中传送的字节流中的每一个字节都按顺序编号。**整个要传送的字节流的起始序号必须在连接建立时设置。首部中的序号字段值则指的是本报文段所发送的数据的第一个字节的序号。例如，一报文段的序号字段值是 301，而携带的数据共有 100字节。这就表明:本报文段的数据的第一个字节的序号是 301 ，最后一个宇节的序号是400。显然，下一个报文段(如果还有的话)的数据序号应当从 401 开始，即下一个报文段的序号字段值应为 401 。这个字段的名称也叫做"报文段序号"。  

- ==确认号==：占 4 字节，是期望收到对方下一个报文段的第一个数据字节的序号。例如， B 正确收到了 A 发送过来的一个报文段，其序号字段值是 501 ，而数据长度是 200 字节(序号 501 - 700) ，这表明 B 正确收到了 A 发送的到序号 700 为止的数据。因此， B 期望收到 A 的下一个数据序号是 701 ，于是 B 在发送给 A 的确认报文段中把确认号置为 701 。  **若确认号 =N， 则表明:到序号 N-1 为止的所有数据都己正确收到。**  

- ==数据偏移==：占 4 位，它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远。这个字段实际上是指出 TCP 报文段的首部长度。由于首部中还有长度不确定的选项宇段，因此数据偏移字段是必要的。但应注意，"数据偏移"的单位是 32 位宇(即以 4 字节长的字为计算单位)。由于 4 位二进制数能够表示的最大十进制数字是 15 ，因此数据偏移的最大值是 60 宇节，这也是 TCP 首部的最大长度(即选项长度不能超过 40 字节）。

- ==保留==： 占 6 位，保留为今后使用，但目前应置为 0 。    

- ==6个控制位==：

  - **紧急 URG (URGent)** ：当 URG = 1 时，表明紧急指针宇段有效。它告诉系统此报文段中有紧急数据，应尽快传送(相当于高优先级的数据)，而不要按原来的排队顺序来传送。例如，己经发送了很长的一个程序要在远地的主机上运行。但后来发现了一些问题，需要取消该程序的运行。因此用户从键盘发出中断命令 (Control + C) 。如果不使用紧急数据，那么这两个字符将存储在接收 TCP 的缓存末尾。只有在所有的数据被处理完毕后这两个字符才被交付接收方的应用进程

    当 URG 置 1 时，发送应用进程就告诉发送方的 TCP 有紧急数据要传送。于是发送方TCP 就把紧急数据插入到本报文段数据的最前面，而在紧急数据后面的数据仍是普通数据。这时要与首部中紧急指针(u电ent Pointer)字段配合使用。

  - **确认 ACK (ACKnowledgment)** ：仅当 ACK= 1 时确认号宇段才有效。当 ACK=0时，确认号无效。 TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1 。  

  - **推送 PSH (PuSH)**  ：当两个应用进程进行交互式的通信时，有时在一端的应用进程希望在键入一个命令后立即就能够收到对方的响应。在这种情况下， TCP 就可以使用推送(push)操作。这时，发送方 TCP 把 PSH 置1，并立即创建一个报文段发迭出去。接收方TCP 收到 PSH= 1 的报文段，就尽快地(即"推送"向前)交付接收应用进程，而不再等到整个缓存都填满了后再向上交付。  

  - **复位 RST** (ReSeT）： 当 RST = 1 时，表明 TCP 连接中出现严重差错(如由于主机崩溃或其他原因)，必须释放连接，然后再重新建立运输连接。 RST 置 1 还用来拒绝一个非法的报文段或拒绝打开一个连接。 RST 也可称为重建位或重置位。  

  - **同步 SYN (SYNchronization**)： 在连接建立时用来同步序号。当 SYN= 1 而 ACK= 0 时，表明这是一个连接请求报文段。对方若同意建立连接，则应在响应的报文段中使SYN=1 和 ACK= 1 。因此， SYN 置为 1 就表示这是一个连接请求或连接接受报文  

  - **终止 FIN** (FINis ，意思是"完"、"终" ) 用来释放一个连接。当 FIN= 1 时，表明此报文段的发送方的数据己发送完毕，并要求释放运输连接。  

- ==窗口==：占 2 字节。窗口值是 [0 ， 2 ^16-1]之间的整数。窗口指的是发送本报文段的一方的接收窗口〈而不是自己的发送窗口〉。窗口值告诉对方:从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量(以字节为单位)。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。总之，窗口值作为接收方让发送方设置其发送窗口的依据。  **窗口字段明确指出了现在允许对方发送的数据量**。窗口值经常在动态变化着。  

- ==检验和==：占 2 字节。检验和字段检验的范围包括首部和数据这两部分。和 UDP用户数据报一样，在计算检验和时，要在 TCP 报文段的前面加上 12 字节的伪首部。伪首部的格式与UDP 用户数据报的伪首部一样。但应把伪首部第 4 个字段中的 17 改为 6(TCP 的协议号是 6) ，把第 5 字段中的 UDP 长度改为 TCP 长度。接收方收到此报文段后，仍要加上这个伪首部来计算检验和。若使用IPv6，则相应的伪首部也要改变。  

- ==紧急指针==：占 2 宇节。紧急指针仅在 URG = 1 时才有意义，它指出本报文段中的紧急数据的字节数(紧急数据结束后就是普通数据)。因此，紧急指针指出了紧急数据的末尾在报文段中的位置。当所有紧急数据都处理完时， TCP 就告诉应用程序恢复到正常操作。值得注意的是，即使窗口为零时也可发送紧急数据。  

- ==选项==： 长度可变，最长可达 40 字节。当没有使用"选项"时， TCP 的首部长度是 20 字节。  

> **选项扩充、MSS**
>
> TCP 最初只规定了一种选项，即**最大报文段长度 MSS (Maximum Segment Size)**  。MSS 是每一个 TCP 报文段中的数据字段的最大长度。数据字段加上 TCP 首部才等于整个的 TCP 报文段。所以 MSS 并不是整个 TCP 报文段的最大长度，而是 "TCP 报文段长度减去 TCP 首部长度"。  
>
> **为什么要规定一个最大报文段长度 MSS 呢?**  
>
> 这并不是考虑接收方的接收缓存可能放不下 TCP 报文段中的数据。实际上， MSS 与接收窗口值没有关系。我们知道， TCP 报文段的数据部分，至少要加上 40 字节的首部 (TCP 首部 20 字节和 IP 首部 20 字节，这里都还没有考虑首部中的选项部分)，才能组装成一个 IP 数据报。若选择较小的 MSS 长度，网络的利用率就降低。设想在极端的情况下，当 TCP 报文段只含有 1 宇节的数据时，在 IP层传输的数据报的开销至少有 40 字节(包括 TCP 报文段的首部和 IP 数据报的首部)。这样，对网络的利用率就不会超过 1/41 。到了数据链路层还要加上一些开销。但反过来，若 TCP 报文段非常长，那么在 IP 层传输时就有可能要分解成多个短数据报片。在终点要把收到的各个短数据报片装配成原来的 TCP 报文段。当传输出错时还要进行重传。这些也都会使开销增大。因此， MSS 应尽可能大些，只要在 IP 层传输时不需要再分片就行。由于 IP 数据报所经历的路径是动态变化的，因此在这条路径上确定的不需要分片的 MSS，如果改走另一条路径就可能需要进行分片。因此最佳的 MSS 是很难确定的。在连接建立的过程中，双方都把自己能够支持的 MSS 写入这一字段，以后就按照这个数值传送数据，两个传送方向可以有不同的 MSS 值。若主机未填写这一项，则 MSS 的默认值是 536 字节长。因此，所有在互联网上的主机都应能接受的报文段长度是 536 +20 (固定首部长度) =556 字节。
>
> 随着互联网的发展，又陆续增加了几个选项。如窗口扩大选项、时间戳选项等(见建议标准 RFC 7323)。以后又增加了有关选择确认(SACK)选项〈见建议标准 RFC 2018)。这些选项的位置都在上图所示的选项字段中。   
>
> **窗口扩大选项**
>
> 窗口扩大选项是为了扩大窗口。我们知道， TCP 首部中窗口宇段长度是 16 位，因此最大的窗口大小为 64K 字节(见下一节〉。虽然这对早期的网络是足够用的，但对于包含卫星信道的网络，传播时延和带宽都很大，要获得高吞吐率需要更大的窗口大小。  
>
> 窗口扩大选项占 3 字节，其中有一个字节表示移位值 S。新的窗口值等于 TCP 首部中的窗口位数从 16 增大到(16 + S)。移位值允许使用的最大值是 14，相当于窗口最大值增大到 2^(16 + 14) -1= 2^30 - 1.窗口扩大选项可以在双方初始建立 TCP 连接时进行协商。如果连接的某一端实现了窗口扩大，当它不再需要扩大其窗口时，可发送 S=0 的选项，使窗口大小回到 16
>
> **时间戳选项**
>
> 时间戳选项占 10 字节，其中最主要的字段是时间戳值字段 (4 字节)和时间戳回送回答字段 (4 字节)。时间戳选项有以下两个功能：
>
> - 用来计算往返时间 RTT。发送方在发送报文段时把当前时钟的时间值放入时间戳字段，接收方在确认该报文段时把时间戳字段值复制到时间戳回送回答字段。因此，发送方在收到确认报文后，可以准确地计算出 RTT 来。
> - 用于处理 TCP 序号超过 2^32 的情况，这又称为防止序号绕回 PAWS (Protect Against Wrapped Sequence numbers)。我们知道， TCP 报文段的序号只有 32 位，而每增加2^32 个序号就会重复使用原来用过的序号。当使用高速网络时，在一次 TCP 连接的数据传送中序号很可能会被重复使用，为了使接收方能区分序号重复的报文段，可以在报文段中加上这种时间戳

TCP 的各种功能和特点都是通过 TCP 报文结构来体现的

### TCP可靠传输的实现

#### 滑动窗口

TCP 的滑动窗口是以字节为单位的  现假定 A 收到了 B 发来的确认报文段，其中窗口是 20 字节，而确认号是 31 (这表明 B 期望收到的下一个序号是 3 1，而序号 30 为止的数据己经收到了)。根据这两个数据， A 就构造出自己的发送窗口  ，如下图所示：（根据B给出的窗口值，A构造出的自己的发送窗口）

![image-20201214195010159](img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201214195010159.png)

发送窗口表示:在没有收到 B 的确认的情况下， A可以连续把窗口内的数据都发送出去。凡是已经发送过的数据，在未收到确认之前都必须暂时保留，以便在超时重传时使用。 

发送窗口里面的序号表示允许发送的序号。显然，窗口越大，发送方就可以在收到对方确认之前连续发送更多的数据，因而可能获得更高的传输效率  。接收方会把自己的接收窗口数值放在窗口字段中发送给对方。因此， A 的发送窗口一定不能超过 B 的接收窗口数值。发送方的发送窗口大小还要受到当时网络拥塞程度的制约。但在目前，我们暂不考虑网络拥塞的影响。  

发送窗口后沿的后面部分表示己发送且己收到了确认。这些数据显然不需要再保留了。而发送窗口前沿的前面部分表示不允许发送的，因为接收方都没有为这部分数据保留临时存放的缓存空间。（上图后沿在左边，前沿在右边）

发送窗口的位置由窗口前沿和后沿的位置共同确定。

发送窗口后沿的变化情况有两种可能，即不动(没有收到新的确认)和前移(收到了新的确认)。发送窗口后沿不可能向后(上图中向左)移动，因为不能撤销掉已收到的确认。  

发送窗口前沿通常是不断向前移动，但也有可能不动。  这对应于两种情况:一是没有收到新的确认，对方通知的窗口大小也不变;二是收到了新的确认但对方通知的窗口缩小了，使得发送窗口前沿正好不动。  

发送窗口前沿也有可能向后收缩。这发生在对方通知的窗口缩小了。但 TCP 的标准强烈不赞成这样做。因为很可能发送方在收到这个通知以前已经发送了窗口中的许多数据，现在又要收缩窗口，不让发送这些数据，这样就会产生一些错误。  

现在假定 A 发送了序号为 31 ~ 41 的数据。这时，发送窗口位置并未改变，如下图：

![image-20201214195426129](img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201214195426129.png)

但发送窗口内靠后面（左边）有 11 个字节(灰色小方框表示)表示已发送但未收到确认。而发送窗口内靠前面（右边）的 9 个字节 (42~50) 是允许发送但尚未发送的。  

从以上所述可以看出，要描述一个发送窗口的状态需要三个指针: P1 P2 和 P3  ，指针都指向宇节的序号。这三个指针指向的几个部分的意义如下:  

- 小于 P1的是已发送并己收到确认的部分，而大于 P3 的是不允许发送的部分。  
- P3 -P1=A 的发送窗口  
- P2 - P1 =已发送但尚未收到确认的字节数  
- P3 - P2 =允许发送但当前尚未发送的字节数(又称为可用窗口或有效窗口)  

再看一下 B 的接收窗口。 B 的接收窗口大小是 20。  如下图：

![image-20201214195712532](img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201214195712532.png)

在接收窗口外面（左面），到 30 号为止的数据是己经发送过确认，并且已经交付主机了  。因此 B 可以不再保留这些数据。接收窗口内的序号（31 ~ 50) 是允许接收的。  

上图中，B 收到了序号为 32 和 33 的数据。这些数据没有按序到达，因为序号为 31 的数据没有收到(也许丢失了，也许滞留在网络中的某处)。请注意， B 只能对按序收到的数据中的最高序号给出确认，因此 B 发送的确认报文段中的确认号==仍然是 31== (即期望收到的序号)，而不能是 32 或 33   没有按序到达的数据，只能先暂存在接收窗口中。  

前面说过：发送方的应用进程把字节流写入 TCP 的发送缓存，接收方的应用进程从 TCP 的接收缓存中读取字节流  

下面进一步讨论窗口和缓存的关系，下图给出了发送方维持的发送缓存和发送窗口，以及接收方
维持的接收缓存和接收窗口。

![image-20201214200720016](img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201214200720016.png)

发送缓存用来暂时存放：

- 发送应用程序传送给发送方 TCP 准备发送的数据
- TCP 己发送出但尚未收到确认的数据。  

发送窗口通常只是发送缓存的一部分。已被确认的数据应当从发送缓存中删除，因此发送缓存和发送窗口的后沿是重合的。发送应用程序最后写入发送缓存的字节减去最后被确认的字节，就是还保留在发送缓存中的被写入的字节数。发送应用程序必须控制写入缓存的速率，不能太快，否则发送缓存就会没有存放数据的空间。 

接收缓存用来暂时存放:  

-  按序到达的、但尚未被接收应用程序读取的数据
- 未按序到达的数据。  

如果收到的分组被检测出有差错，则要丢弃。如果接收应用程序来不及读取收到的数据，接收缓存最终就会被填满，使接收窗口减小到零。反之，如果接收应用程序能够及时从接收缓存中读取收到的数据，接收窗口就可以增大，但最大不能超过接收缓存的大小。  上图右侧还指出了下一个期望收到的字节号。这个字节号也就是接收方给发送方的报文段的首部中的确认号。  

注意：

- 对于不按序到达的数据应如何处理， TCP 标准并无明确规定。如果接收方把不按序到达的数据一律丢弃，那么接收窗口的管理将会比较简单，但这样做对网络资源的利用不利(因为发送方会重复传送较多的数据〉。因此 TCP 通常对不按序到达的数据是先临时存放在接收窗口中，等到字节流中所缺少的字节收到后，再接序交付上层的应用进程。  
- TCP 要求接收方必须有累积确认的功能，这样可以减小传输开销。接收方可以在合适的时候发送确认，也可以在自己有数据要发送时把确认信息顺便捎带上。但请注意两点。一是接收方不应过分推迟发送确认，否则会导致发送方不必要的重传，这反而浪费了网络的资源。 TCP 标准规定，确认推迟的时间不应超过 0.5 秒。若收到一连串具有最大长度的报文段，则必须每隔一个报文段就发送一个确认二是捎带确认实际上并不经常发生，因为大多数应用程序很少同时在两个方向上发送数据。  
- TCP 的通信是全双工通信。通信中的每一方都在发送和接收报文段。因此，每一方都有自己的发送窗口和接收窗口。在谈到这些窗口时，一定要弄清是哪一方的窗口。  

#### 超时重传时间的选择

上面已经讲到， TCP 的发送方在规定的时间内没有收到确认就要重传己发送的报文段。这种重传的概念是很简单的，但重传时间的选择却是 TCP 最复杂的问题之一。  

由于 TCP 的下层是互联网环境，发送的报文段可能只经过一个高速率的局域网，也可能经过多个低速率的网络，并且每个 IP 数据报所选择的路由还可能不同。如果把超时重传时间设置得太短，就会引起很多报文段的不必要的重传，使网络负荷增大。但若把超时重传时间设置得过长，则又使网络的空闲时间增大，降低了传输效率。
那么，运输层的超时计时器的超时重传时间究竟应设置为多大呢?  

TCP 采用了一种自适应算法，它记录一个报文段发出的时间，以及收到相应的确认的时间。这两个时间之差就是报文段的往返时间 ==RTT==  (Round Trip Time)

TCP 保留了 RTT 的一个加权平均往返时间 RTTs (这又称为平滑的往返时间， S 表示 Smoothed。因为进行的是加权平均，因此得出的结果更加平滑)。每当第一次测量到 RTT 样本时， RTTs 值就取为所测量到的 RTT 样本值。但以后每测量到一个新的 RTT 样本，就按公式重新计算一次 RTTs 

超时计时器设置的超时重传时间 ==RTO==  (RetransmissionTime-Out)应略大于上面得出的加权平均往返时间 RTTs 

#### 选择确认SACK

若收到的报文段无差错，只是未按序号，中间还缺少一些序号的数据，那么能否设法只传送缺少的数据而不重传已经正确到达接收方的数据?  答案是可以的。选择确认（Selective ACK）就是一种可行的处理方法。  

下面用一个例子来说明选择确认(Selective ACK)的工作原理  

TCP 的接收方在接收对方发送过来的数据字节流的序号不连续，结果就形成了一些不连续的字节块(如下图所
示)。可以看出，序号 1 ~ 1000 收到了，但序号 1001 ~ 1500 没有收到。接下来的宇节流又收到了，可是又缺少了 3001 ~ 3500。再后面从序号 4501 起又没有收到。也就是说，接收方收到了和前面的字节流不连续的两个字节块。如果这些字节的序号都在接收窗口之内，那么接收方就先收下这些数据，但要把这些信息准确地告诉发送方，使发送方不要再重复发送这些己收到的数据。

![image-20201214202807818](img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201214202807818.png)  

从上图可以看出，前后字节不连续的每一个字节块都有两个边界:左边界和右边界。因此在图中用四个指针标记这些边界。请注意，第一个字节块的左边界 L1 = 1501，但右边界 R1 = 3001 而不是 3000。这就是说，左边界指出字节块的第一个字节的序号，但右边界减 1 才是字节块中的最后一个序号。同理，第二个字节块的左边界 L2 = 3501，而右边界R2 =4501 。  

我们知道， TCP 的首部没有哪个字段能够提供上述这些字节块的边界信息。RFC 2018规定，如果要使用选择确认 SACK，那么在建立 TCP 连接时，就要在 TCP 首部的选项中加上"允许 SACK" 的选项，而双方必须都事先商定好。如果使用选择确认，那么原来首部中的"确认号宇段"的用法仍然不变。只是以后在 TCP 报文段的首部中都增加了 SACK 选项，以便报告收到的不连续的字节块的边界。由于首部选项的长度最多只有 40 字节，而指明一个边界就要用掉 4 字节(因为序号有 32 位，需要使用 4 个字节表示)，因此在选项中最多只能指明 4 个字节块的边界信息。这是因为 4 个宇节块共有 8 个边界，因而需要用 32 个字节来描述。另外还需要两个宇节。一个字节用来指明是 SACK 选项，另一个字节是指明这个选项要占用多少字节。如果要报告五个字节块的边界信息，那么至少需要 42 个字节。这就超过了选项长度的 40 字节的上限。互联网建议标准 RFC 2018 还对报告这些边界信息
的格式都做出了非常明确的规定，这里从略。

然而， SACK 文档并没有指明发送方应当怎样响应 SACK。因此大多数的实现还是重传
所有未被确认的数据块。  

### 序号、确认号实现传输可靠性

TCP 报文段首部中两个最重要的字段就是 `序号` 和 `确认号`，这两个字段是 TCP 实现可靠性的基础，那么你肯定好奇如何实现可靠性呢？要了解这一点，首先我们得先知道这两个字段里面存了哪些内容吧？

**一个报文段的序号就是数据流的字节编号** 。因为 TCP 会把数据流分割成为一段一段的字节流，因为字节流本身是有序的，所以每一段的字节编号就是标示是哪一段的字节流。比如，主机 A 要给主机 B 发送一条数据。数据经过应用层产生后会有一串数据流，数据流会经过 TCP 分割，分割的依据就是 MSS，假设数据是 10000 字节，MSS 是 2000 字节，那么 TCP 就会把数据拆分成 0 - 1999 , 2000 - 3999 的段，依次类推。

所以，第一个数据 0 - 1999 的首字节编号就是 0 ，2000 - 3999 的首字节编号就是 2000 。

然后，每个序号都会被填入 TCP 报文段首部的序号字段中。

<img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213184858726.png" alt="image-20201213184858726" style="zoom:50%;" />

至于确认号的话，会比序号要稍微麻烦一些。这里我们先拓展下几种通信模型。

### 通信模型

- 单工通信：单工数据传输只支持数据在一个方向上传输；在同一时间只有一方能接受或发送信息，不能实现双向通信，比如广播、电视等。
- 双工通信是一种点对点系统，由两个或者多个在两个方向上相互通信的连接方或者设备组成。双工通信模型有两种：全双工(FDX)和半双工(HDX)
- 全双工：在全双工系统中，连接双方可以相互通信，一个最常见的例子就是电话通信。全双工通信是两个单工通信方式的结合，它要求发送设备和接收设备都有独立的接收和发送能力。
- 半双工：在半双工系统中，连接双方可以彼此通信，但不能同时通信，比如对讲机，只有把按钮按住的人才能够讲话，只有一个人讲完话后另外一个人才能讲话。

单工、半双工、全双工通信如下图所示

<img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213185010486.png" alt="image-20201213185010486" style="zoom:50%;" />

TCP 是一种全双工的通信协议，因此主机 A 在向主机 B 发送消息的过程中，也在接受来自主机 B 的数据。主机 A 填充进报文段的确认号是期望从主机 B 收到的下一字节的序号。稍微有点绕，我们来举个例子看一下。比如主机 A 收到了来自主机 B 发送的编号为 0 - 999 字节的报文段，这个报文段会写入序号中，随后主机 A 期望能够从主机 B 收到 1000 - 剩下的报文段，因此，主机 A 发送到主机 B 的报文段中，它的确认号就是 1000 。

### 累积确认

这里再举出一个例子，比如主机 A 在发送 0 - 999 报文段后，期望能够接受到 1000 之后的报文段，但是主机 B 却给主机 A 发送了一个 1500 之后的报文段，那么主机 A 是否还会继续进行等待呢？

答案显然是会的，因为 TCP 只会确认流中至第一个丢失字节为止的字节，因为 1500 虽然属于 1000 之后的字节，但是主机 B 没有给主机 A 发送 1000 - 1499 之间的字节，所以主机 A 会继续等待。

在了解完序号和确认号之后，我们下面来聊一下 TCP 的发送过程。下面是一个正常的发送过程

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213185125908.png" alt="image-20201213185125908" style="zoom:30%;" />

TCP 通过肯定的`确认应答(ACK)` 来实现可靠的数据传输，当主机 A将数据发出之后会等待主机 B 的响应。如果有确认应答(ACK)，说明数据已经成功到达对端。反之，则数据很可能会丢失。

如下图所示，如果在一定时间内主机 A 没有等到确认应答，则认为主机 B 发送的报文段已经丢失，并进行重发。

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213185156104.png" alt="image-20201213185156104" style="zoom:40%;" />

主机 A 给主机 B 的响应可能由于网络抖动等原因无法到达，那么在经过特定的时间间隔后，主机 A 将重新发送报文段。

主机 A 没有收到主机 B 的响应还可能是因为主机 B 在发送给主机 A 的过程中丢失。

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213185230351.png" alt="image-20201213185230351" style="zoom:50%;" />

如上图所示，由主机 B 返回的确认应答，由于网络拥堵等原因在传送的过程中丢失，并没有到达主机 A。主机 A 会等待一段时间，如果在这段时间内主机 A 仍没有等到主机 B 的响应，那么主机 A 会重新发送报文段。

那么现在就存在一个问题，如果主机 A 给主机 B 发送了一个报文段后，主机 B 接受到报文段发送响应，此刻由于网络原因，这个报文段并未到达，等到一段时间后主机 A 重新发送报文段，然后此时主机 B 发送的响应在主机 A 第二次发送后失序到达主机 A，那么主机 A 应该如何处理呢？

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213185309796.png" alt="image-20201213185309796" style="zoom:40%;" />

TCP RFC 并未为此做任何规定，也就是说，我们可以自己决定如何处理失序到达的报文段。一般处理方式有两种

- 接收方立刻丢弃失序的报文段
- 接收方接受失序到达的报文段，并等待后续的报文段

一般来说通常采取的做法是第二种。

### 传输控制

#### 利用窗口控制提高速度

前面我们介绍了 TCP 是以数据段的形式进行发送，如果经过一段时间内主机 A 等不到主机 B 的响应，主机 A 就会重新发送报文段，接受到主机 B 的响应，再会继续发送后面的报文段，我们现在看到，这一问一答的形式还存在许多条件，比如响应未收到、等待响应等，那么对崇尚性能的互联网来说，这种形式的性能应该不会很高。

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213185404112.png" alt="image-20201213185404112" style="zoom:50%;" />

> 那么如何提升性能呢？

为了解决这个问题，TCP 引入了 `窗口` 这个概念，即使在往返时间较长、频次很多的情况下，它也能控制网络性能的下降，听起来很牛批，那它是如何实现的呢？

如下图所示

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213185430181.png" alt="image-20201213185430181" style="zoom:50%;" />

我们之前每次请求发送都是以报文段的形式进行的，引入窗口后，每次请求都可以发送多个报文段，也就是说一个窗口可以发送多个报文段。窗口大小就是指无需等待确认应答就可以继续发送报文段的最大值。

在这个窗口机制中，大量使用了 `缓冲区` ，通过对多个段同时进行确认应答的功能。

如下图所示，发送报文段中高亮部分即是我们提到的窗口，在窗口内，即使没有收到确认应答也可以把请求发送出去。不过，在整个窗口的确认应答没有到达之前，如果部分报文段丢失，那么主机 A 将仍会重传。为此，主机 A 需要设置缓存来保留这些需要重传的报文段，直到收到他们的确认应答。

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213185502967.png" alt="image-20201213185502967" style="zoom:50%;" />

在滑动窗口以外的部分是尚未发送的报文段和已经接受到的报文段，如果报文段已经收到确认则不可进行重发，此时报文段就可以从缓冲区中清除。

在收到确认的情况下，会将窗口滑动到确认应答中确认号的位置，如上图所示，这样可以顺序的将多个段同时发送，用以提高通信性能，这种窗口也叫做 `滑动窗口(Sliding window)`。

#### 窗口控制和重发

报文段的发送和接收，必然伴随着报文段的丢失和重发，窗口也是同样如此，如果在窗口中报文段发送过程中出现丢失怎么办？

首先我们先考虑确认应答没有返回的情况。在这种情况下，主机 A 发送的报文段到达主机 B，是不需要再进行重发的。这和单个报文段的发送不一样，如果发送单个报文段，**即使确认应答没有返回，也要进行重发**。

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213185540374.png" alt="image-20201213185540374" style="zoom:50%;" />

窗口在一定程度上比较大时，即使有少部分确认应答的丢失，也不会重新发送报文段。

我们知道，如果在某个情况下由于发送的报文段丢失，导致接受主机未收到请求，或者主机返回的响应未到达客户端的话，会经过一段时间重传报文。那么在使用窗口的情况下，报文段丢失会怎么样呢？

如下图所示，报文段 0 - 999 丢失后，但是主机 A 并不会等待，主机 A 会继续发送余下的报文段，主机 B 发送的确认应答却一直是 1000，同一个确认号的应答报文会被持续不断的返回，如果发送端主机在连续 3 次收到同一个确认应答后，就会将其所对应的数据重发，这种机制要比之前提到的超时重发更加高效，这种机制也被称为 `高速重发控制`。这种重发的确认应答也被称为 `冗余 ACK(响应)`。

主机 B 在没有接收到自己期望序列号的报文段时，会对之前收到的数据进行确认应答。发送端则一旦收到某个确认应答后，又连续三次收到同样的确认应答，那么就会认为报文段已经丢失。需要进行重发。使用这种机制可以提供更为快速的重发服务。

### 流量控制

前面聊的是传输控制，下面 聊一下 `流量控制`。

一般说来，我们总是希望数据传输得更快一些。但如果发送方把数据发送得过快，接收方就可能来不及接收，这就会造成数据的丢失。所谓流量控制(flow control)就是让发送方的发送速率不要太快，要让接收方来得及接收。  

我们知道，在每个 TCP 连接的一侧主机都会有一个 socket 缓冲区，缓冲区会为每个连接设置接收缓存和发送缓存，当 TCP 建立连接后，从应用程序产生的数据就会到达接收方的接收缓冲区中，接收方的应用程序并不一定会马上读取缓冲区的数据，它需要等待操作系统分配时间片。如果此时发送方的应用程序产生数据过快，而接收方读取接受缓冲区的数据相对较慢的话，那么接收方中缓冲区的数据将会`溢出`。

但是还好，TCP 有 `流量控制服务(flow-control service)` 用于消除缓冲区溢出的情况。流量控制是一个速度匹配服务，即发送方的发送速率与接受方应用程序的读取速率相匹配。

TCP 通过使用一个 `接收窗口(receive window)` 的变量来提供流量控制。接受窗口会给发送方一个指示**到底还有多少可用的缓存空间**。发送端会根据接收端的实际接受能力来控制发送的数据量。

接收端主机向发送端主机通知自己可以接收数据的大小，发送端会发送不超过这个限度的数据，这个大小限度就是窗口大小，还记得 TCP 的首部么，有一个接收窗口，我们上面聊的时候说这个字段用于流量控制。它用于指示接收方能够/愿意接受的字节数量。

> 那么只知道这个字段用于流量控制，那么如何控制呢？

发送端主机会定期发送一个`窗口探测包`，这个包用于探测接收端主机是否还能够接受数据，当接收端的缓冲区一旦面临数据溢出的风险时，窗口大小的值也随之被设置为一个更小的值通知发送端，从而控制数据发送量。

下面是一个流量控制示意图

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9B%BE%E8%A7%A3TCP%E3%80%81UDP%E5%8D%8F%E8%AE%AE.img/image-20201213185638737.png" alt="image-20201213185638737" style="zoom:50%;" />

发送端主机根据接收端主机的窗口大小进行流量控制。由此也可以防止发送端主机一次发送过大数据导致接收端主机无法处理。

如上图所示，当主机 B 收到报文段 2000 - 2999 之后缓冲区已满，不得不暂时停止接收数据。然后主机 A 发送窗口探测包，窗口探测包非常小仅仅一个字节。然后主机 B 更新缓冲区接收窗口大小并发送窗口更新通知给主机 A，然后主机 A 再继续发送报文段。

在上面的发送过程中，窗口更新通知可能会丢失，一旦丢失发送端就不会发送数据，所以窗口探测包会定时发送，以避免这种情况发生。

现在我们考虑一种情况。 B 向 A 发送了零窗口的报文段后不久， B 的接收缓存又有了一些存储空间。于是 B 向 A 发送了 rwnd = 400 的报文段。然而这个报文段在传送过程中丢失了。 A 一直等待收到 B 发送的非零窗口的通知，而 B 也一直等待 A 发送的数据。如果没有其他措施，这种互相等待的死锁局面将一直延续下去。

为了解决这个问题， TCP 为每一个连接设有一个持续计时器(persistence timer) 。只要TCP 连接的一方收到对方的零窗口通知，就启动持续计时器。若持续计时器设置的时间到期，就发送一个零窗口探测报文段(仅携带 1 字节的数据)，而对方就在确认这个探测报文段时给出了现在的窗口值。如果窗口仍然是零，那么收到这个报文段的一方就重新设置持续计时器。如果窗口不是零，那么死锁的僵局就可以打破了。    

### TCP的传输效率

#### 零窗口问题

零窗口问题：如果接收通告窗口为0，则发送端怎么处理？

发送方维护坚持定时器，窗口探查

如果接收方没有能力接收数据，就会将接收窗口设置为0，这时发送方必须暂停发送数据，但是会启动一个持续计时器（persistence timer），到期后会发送一个大小为1字节的探测数据包，以查看接收窗口状态。如果接收方能够接收数据，就会在返回的报文中更新接收窗口大小，发送方就可以根据该大小恢复数据的发送

#### Nagle算法

Nagle算法：避免发送小的数据包。要求TCP连接上最多只能有一个未被确认的小分组。在该分组的确认到达之前不能发送其他小分组。同时TCP收集这些小分组，并在确认到来时以一个整体的较大分组发送出去

若发送应用进程把要发送的数据逐个字节地送到 TCP 的发送缓存，则发送方就把第一个数据字节先发送出去，把后面到达的数据字节都缓存起来。当发送方收到对第一个数据字符的确认后，再把发送缓存中的所有数据组装成一个报文段发送出去，同时继续对随后到达的数据进行缓存。只有在收到对前一个报文段的确认后才继续发送下一个报文段。

当数据到达较快而网络速率较慢时，用这样的方法可明显地减少所用的网络带宽。 Nagle 算法还规定，当到达的数据已达到发送窗口大小的一半或己达到报文段的最大长度时，就立即发送一个报文段。这样做，就可以有效地提高网络的吞吐量。  

总结如下：

Nagle算法：尽量减少小数量的发送，在以下两条件之一满足之前，就会一直积累待发数据

- 收到之前发送的报文段之前
- 积累的数据量达到MSS或者到发送窗口（接收通告窗口）的一半

#### 糊涂窗口综合征

糊涂窗口综合征（silly window syndrome）：TCP 接收方的缓存己满，而交互式的应用进程一次只从接收缓
存中读取 1 个字节(这样就使接收缓存空间仅腾出 1 个宇节)，然后向发送方发送确认，并把窗口设置为 1 个字节(但发送的数据报是 40 字节长)。接着，发送方又发来 1 个宇节的数据(请注意，发送方发送的 IP 数据报是 41 字节长〉。接收方发回确认，仍然将窗口设置为1 个字节。这样进行下去，使网络的效率很低。  

即当发送端应用进程产生数据很慢、或接收端应用进程处理接收缓冲区数据很慢，或二者兼而有之；就会使应用进程间传送的报文段很小，特别是有效载荷很小； 极端情况下，有效载荷可能只有1个字节；传输开销有40字节(20字节的IP头+20字节的TCP头) 这种现象。

总结如下：

糊涂窗口综合征：窗口大小从0变为非0，非0值没有特别大，如果不加控制则发送方会发送小数据。使得发送数据的效率低下。解决方案：

- 接收方不通告小窗口：如果窗口大小没有达到MSS或者接收缓冲区的一半，则不告知发送方窗口为非0值
- 发送方满足以下条件之一才发送数据：1.可以发送一个满长度的（MSS）的报文段 2.可以发送至少是接收方通告窗口大小一半的报文段  3.还有未被确认的数据

### TCP运输连接管理

TCP 是面向连接的协议。运输连接是用来传送 TCP 报文的。 TCP 运输连接的建立和释放是每一次面向连接的通信中必不可少的过程。因此，运输连接就有三个阶段，即:连接建立、数据传送和连接释放。  

TCP 连接的建立采用客户服务器方式。主动发起连接建立的应用进程叫做客户 (client) ，而被动等待连接建立的应用进程叫做服务器(server) 。

#### TCP连接的建立

TCP 建立连接的过程叫做握手，握手需要在客户和服务器之间交换三个 TCP 报文段。    三次握手建立连接如下图：

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20210102135136113.png" alt="image-20210102135136113" style="zoom:67%;" />

假定主机 A 运行的是 TCP 客户程序，而 B 运行 TCP 服务器程序。最初两端的 TCP 进程都处于 CLOSED (关闭)状态。图中在主机下面的方框分别是 TCP 进程所处的状态。在本例中， A 主动打开连接，而 B 被动打开连接。  

一开始， B 的 TCP 服务器进程先创建传输控制块 TCB，准备接受客户进程的连接请求。然后服务器进程就处于 ==LISTEN== (收听)状态，等待客户的连接请求。如有，即作出响应。  

>传输控制块 TCB (Transmission Control Block)存储了每一个连接中的一些重要信息，如: TCP 连接表，指向发送和接收缓存的指针，指向重传队列的指针，当前的发送和接收序号，等等。  

A 的 TCP 客户进程也是首先创建传输控制模块 TCB。然后，在打算建立 TCP 连接时，向 B 发出连接请求报文段，这时首部中的同步位 SYN = 1 ，同时选择一个初始序号 seq =x， TCP 规定， SYN 报文段(即 SYN= 1 的报文段)不能携带数据，但要消耗掉一个序号。这时， TCP 客户进程进入 ==SYN-SENT== (同步己发送)状态。  

B 收到连接请求报文段后，如同意建立连接，则向 A 发送确认。在确认报文段中应把SYN 位和 ACK 位都置 1 ，确认号是 ack = X + 1，同时也为自己选择一个初始序号 seq = y 。注意，这个报文段也不能携带数据，但同样要消耗掉一个序号。这时 TCP 服务器进程进入==SYN-RCVD== (同步收到)状态。  

TCP 客户进程收到 B 的确认后，还要向 B 给出确认。确认报文段的 ACK 置 1 ，确认号ack=y+ L 而自己的序号 seq = x + 10 TCP 的标准规定， **ACK 报文段可以携带数据**。但如果不携带数据则不消耗序号，在这种情况下，下一个数据报文段的序号仍是 seq=x+l 。这时， TCP 连接己经建立， A 进入 ==ESTABLISHED== (己建立连接)状态。  

当 B 收到 A 的确认后，也进入 ==ESTABLISHED== 状态。  

#### 为什么需要三次握手？

可不可以两次握手呢？为什么 A 最后还要发送一次确认呢?

答：这主要是为了==防止己失效的连接请求报文段突然又传送到了 B== ，因而产生错误。  

考虑一种正常情况， A 发出连接请求，但因连接请求报文丢失而未收到确认。于是 A 再重传一次连接请求。后来收到了确认，建立了连接。数据传输完毕后，就释放了连接。 A 共发送了两个连接请求报文段，其中
第一个丢失，第二个到达了 B ，没有"己失效的连接请求报文段"。  

现假定出现一种异常情况，即 A 发出的第一个连接请求报文段并没有丢失，而是在某些网络结点长时间滞留了，以致延误到连接释放以后的某个时间才到达 B。本来这是一个早已失效的报文段。但 B 收到此失效的连接请求报文段后，就误认为是 A 又发出一次新的连接请求。于是就向 A 发出确认报文段，同意建立连接。假定不采用第三次报文握手，那么只要 B发出确认，新的连接就建立了。  

由于现在 A 并没有发出建立连接的请求，因此不会理睬 B 的确认，也不会向 B 发送数据。但 B 却以为新的运输连接己经建立了，并一直等待 A 发来数据。 B 的许多资源就这样白白浪费了。  

采用三报文握手的办法，可以防止上述现象的发生。例如在刚才的异常情况下， A 不会向 B 的确认发出确认。 B 由于收不到确认，就知道 A 并没有要求建立连接。  

#### TCP连接的释放

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20210102135249279.png" alt="image-20210102135249279" style="zoom:67%;" />

数据传输结束后，通信的双方都可释放连接。现在 A 和 B 都处于 ESTABLISHED 状态， A 的应用进程先向其 TCP 发出连接释放报文段，并停止再发送数据，主动关闭TCP 连接。 A 把连接释放报文段首部的终止控制位 FIN 置 1 ，其序号 seq = u ，它等于前面己传送过的数据的最后一个字节的序号加 1 。这时 A 进入 ==FIN-WAI下 1== (终止等待 1 )状态，等待 B 的确认。请注意， TCP 规定， FIN 报文段即使不携带数据，它也消耗掉一个序号。  

B 收到连接释放报文段后即发出确认，确认号是 ack = u + 1，而这个报文段自己的序号是 v，等于 B 前面己传送过的数据的最后一个字节的序号加 1 。然后 B 就进入 ==CLOSEWAIT== (关闭等待)状态。 TCP 服务器进程这时应通知高层应用进程，因而从 A 到 B 这个方向的连接就释放了，这时的 TCP 连接处于半关闭 (half-c1ose)状态，即 A 已经没有数据要发送了，但 B 若发送数据， A 仍要接收。也就是说，从 B 到 A 这个方向的连接并未关闭，这个状态可能会持续一段时间。  

A 收到来自 B 的确认后，就进入 ==FIN-WAIT-2== (终止等待 2) 状态，等待 B 发出的连接释放报文段。  

若 B 己经没有要向 A 发送的数据，其应用进程就通知 TCP 释放连接。这时 B 发出的连接释放报文段必须使 FIN = 1 。现假定 B 的序号为 w (在半关闭状态 B 可能又发送了一些数据 ). B 还必须重复上次已发送过的确认号 ack = u + 1 。这时 B 就进入 ==LAST-ACK== (最后确认)状态，等待 A 的确认。  

A 在收到 B 的连接释放报文段后，必须对此发出确认。在确认报文段中把 ACK 置1，确认号 ack = w + 1 ，而自己的序号是 seq=u+1 (根据 TCP 标准，前面发送过的 FIN 报文段要消耗一个序号)。然后进入到 ==TIME-WAIT== (时间等待)状态。请注意，现在 TCP 连接还没有释放掉。必须经过时间等待计时器(TIME-WAIT timer)设置的时间 2MSL 后， A 才进入到 CLOSED 状态。

> 时间 MSL 叫做最长报文段寿命(Maximum Segment Lifetime)，RFC 793建议设为 2 分钟。但这完全是从工程上来考虑的，对于现在的网络， MSL = 2 分钟可能太长了一些。因此 TCP 允许不同的实现可根据具体情况使用更小的 MSL 值。

因此，从 A 进入到 TIME-WAIT 状态后，要经过 2MSL才能进入到 CLOSED 状态，才能开始建立下一个新的连接。当 A 撤销相应的传输控制块 TCB 后，就结束了这次的 TCP 连接。    

#### SYN攻击

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20210102155925900.png" alt="image-20210102155925900" style="zoom:67%;" />

#### 等待 2MSL 的时间的原因

**第一，为了保证 A 发送的最后一个 ACK 报文段能够到达 B 。**

这个 ACK 报文段有可能丢失，因而使处在 LAS下ACK 状态的 B 收不到对已发送的 FIN + ACK 报文段的确认。 B 会超时重传这个 FIN+ACK 报文段，而 A 就能在 2MSL 时间内收到这个重传的 FIN + ACK 报文段。接着 A 重传一次确认，重新启动 2MSL 计时器。最后， A 和 B 都正常进入到CLOSED 状态。如果 A 在 TIME-WAIT 状态不等待一段时间，而是在发送完 ACK 报文段后立即释放连接，那么就无法收到 B 重传的 FIN + ACK 报文段，因而也不会再发送一次确认报文段。这样， B 就无法按照正常步骤进入 CLOSED 状态。    

**第二，防止"己失效的连接请求报文段"出现在本连接中。**  

A 在发送完最后一个 ACK 报文段后，再经过时间 2MSL 就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。  

B 只要收到了 A 发出的确认，就进入 CLOSED 状态。同样， B 在撤销相应的传输控制块 TCB 后，就结束了这次的 TCP 连接。我们注意到， B 结束 TCP 连接的时间要比 A 早一些  

#### 保活计时器

keepaliver timer

设想有这样的情况:客户己主动与服务器建立了 TCP 连接。但后来客户端的主机突然出故障。显然，服务器以后就不能再收到客户发来的数据。因此，应当有措施使服务器不要再白白等待下去。这就要使用保活计时器。服务器每收到一次客户的数据，就重新设置保活计时器，时间的设置通常是两小时。若两小时没有收到客户的数据，服务器就发送一个探测报文段，以后则每隔75 秒钟发送一次。若一连发送 10 个探测报文段后仍无客户的响应，服务器就认为客户端出了故障，接着就关闭这个连接。  

#### TCP有限状态机

方框：可能具有的状态

箭头：可能发生的状态变迁

箭头旁边的字：引起变迁的原因、状态变迁的动作

粗实线箭头：对客户进程的正常变迁

粗虚线箭头：对服务器进程的正常变迁

细实线箭头：异常变迁

![image-20210102134810016](img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20210102134810016.png)

可以把三次握手、四次挥手图与本图对照起来看，三次握手四次挥手示意图中左边客户进程从上到下的状态变迁（黄色块），就是上图中粗实线箭头所指的变迁，服务器进程从上到下的状态变迁（蓝色快），就是上图粗虚线所指的状态变迁

### 拥塞控制

**网络拥塞**：若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫做拥塞(congestion)  

**拥塞控制**：拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载  

**拥塞控制与流量控制**的关系密切，它们之间也存在着一些差别。拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载，拥塞控制是一个全局性的过程，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是指点对点通信量的控制，是个端到端的问题(接收端控制发送端)。流量控制所要做的就是抑制发送端发送数据的速率，以便使接收端来得及接收。  

- 拥塞控制：全局，防止过多的数据注入到网络中
- 流量控制：端到端，是抑制发送端发送数据的速率，以便使接收端来得及接收。  

#### TCP 拥塞控制

TCP 进行拥塞控制的算法有四种

- 慢启动（slow-start）
- 拥塞避免（congestion avoidance）
- 快重传（fast retransmit）
- 快恢复（fast recovery）

下面讨论的拥塞控制也叫做基于窗口的拥塞控制。为此，发送方维持一个叫做拥塞窗口 cwnd (congestion window)的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。  

发送方控制拥塞窗口的原则是:只要网络没有出现拥塞，拥塞窗口就可以再增大一些，以便把更多的分组发送出去，这样就可以提高网络的利用率。但只要网络出现拥塞或有可能出现拥塞，就必须把拥塞窗口减小一些，以减少注入到网络中的分组数，以便缓解网络出现的拥塞。  

#### 慢启动

当主机开始发送数据时，由于并不清楚网络的负荷情况，所以如果立即把大量数据字节注入到网络，那么就有可能引起网络发生拥塞。经验证明，较好的方法是先探测一下，即==由小到大逐渐增大发送窗口==，也就是说，由小到大逐渐增大拥塞窗口数值。  

在一开始发送方先设置 cwnd = 1 ，发送第一个报文段 Ml，接收方收到后确认 M1 。发送方收到对 M1 的确认后，把 cwnd 从 1 增大到 2 ，于是发送方接着发送 M2 和 M3 两个报文段。接收方收到后发回对 M2 和 M3 的确认。发送方每收到一个对新报文段的确认(重传的不算在内)就使发送方的拥塞窗口加1，因此发送方在收到两个确认后， cwnd 就从 2 增大到 4，并可发送~ ~ M7 共 4 个报文段(见下图) 。因此使用慢开始算法后，每经过一个
传输轮次(transmission round) ，拥塞窗口 cwnd 就加倍。  

![image-20201229204508219](img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201229204508219.png)

慢开始的"慢"并不是指 cwnd 的增长速率慢，而是指在 TCP 开始发送报文段时先设置 cwnd= 1 ，使得发送方在开始时只发送一个报文段(目的是试探一下网络的拥塞情况) ，然后再逐渐增大 cwnd。这当然比设置大的 cwnd 值一下子把许多报文段注入到网络中要"慢得多"。这对防止网络出现拥塞是一个非常好的方法。  

为了防止拥塞窗口 cwnd 增长过大引起网络拥塞，还需要设置一个慢开始门限 ssthresh(Slow start threshold)状态变量。慢开始门限 ssthresh 的用法如下:  

- 当 cwnd < ssthresh 时，使用上述的慢开始算法。
- 当 cwnd > ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。
- 当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞避免算法。  

#### 拥塞避免

拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢地增大，即每经过一个往返时间 RTT 就把发送方的拥塞窗口 cwnd 加 1，而不是像开始阶段那样加倍增长。因此在拥塞避免阶段就有"加法增大" AI (Additive Increase)的特点。这表明在拥塞避免阶段，==拥塞窗口 cwnd 按线性规律缓慢增长==，比慢开始算法的拥塞窗口增长速率缓慢得多。 

"拥塞避免"并非完全能够避免了拥塞。"拥塞避免"是说把拥塞窗口控制为按线性规律增长，使网络比较不容易出现拥塞。   

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201229205418861.png" alt="image-20201229205418861" style="zoom:67%;" />

#### 快重传

有时，个别报文段会在网络中丢失，但实际上网络并未发生拥塞。如果发送方迟迟收不到确认，就会产生超时，就会误认为网络发生了拥塞。这就导致发送方错误地启动慢开始，把拥塞窗口 cwnd 又设置为1，因而降低了传输效率。  

快重传算法可以让发送方尽早知道发生了个别报文段的丢失。快重传算法首先要求接收方不要等待自己发送数据时才进行捎带确认，而是要立即发送确认，即使收到了失序的报文段也要立即发出对己收到的报文段的重复确认  

如下图所示，接收方收到了 M1 和M2 后都分别及时发出了确认。现假定接收方没有收到 M3 但却收到了 M4 ，本来接收方可以什么都不做。但按照快重传算法，接收方必须立即发送对 M2 的重复确认，以便让发送方及早知道接收方没有收到报文段 M3。 发送方接着发送 M5 和 M6。接收方收到后也仍要再次分别发出对 M2 的重复确认。这样，发送方共收到了接收方的 4 个对 M2 的确认，其中后 3 个都是重复确认。

快重传算法规定，==发送方只要一连收到 3 个重复确认，就知道接收方确实没有收到报文段 M3'== 因而应当立即进行重传(即"快重传“），这样就不会出现超时，发送方也不就会误认为出现了网络拥塞。使用快重传可以使整个网络的吞吐量提高约 20% 。  

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201229205838604.png" alt="image-20201229205838604" style="zoom:67%;" />

#### 快恢复

![image-20201229210016861](img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20201229210016861.png)

在上图 中的点 4，发送方知道现在只是丢失了个别的报文段。于是不启动慢开始，而是执行快恢复算法。这时，==发送方调整门限值 ssthresh = cwnd / 2 = 8== ，同时设置拥塞窗口 cwnd = ssthresh = 8 (见图 点 5) ，并开始执行拥塞避免算法

在拥塞避免阶段，拥塞窗口是按照线性规律增大的，这常称为加法增大 AI (Additive Increase)。而一旦出现超时或 3 个重复的确认，就要把门限值设置为当前拥塞窗口值的一半，井大大减小拥塞窗口的数值。这常称为"乘法减小" MD(Multiplicative Decrease)。二者合在一起就是所谓的 AIMD 算法。  

TCP 的拥塞控制可以归纳为图 所示 的流程图 

 <img src="img/%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%BF%90%E8%BE%93%E5%B1%82%E3%80%81TCP%E3%80%81UDP.img/image-20210102122159558.png" alt="image-20210102122159558" style="zoom:67%;" />

#### 发送方窗口值

接收方根据自己的接收能力设定了接收方窗口rwnd，并把这个窗口值写入 TCP 首部中的窗口字段，传送给发送方。因此，接收方窗口又称为通知窗口 (advertised window)。因此，从接收方对发送方的流量控制的角度考虑，**发送方的发送窗口一定不能超过对方给出的接收方窗口值 rwnd。**  

如果把本节所讨论的拥塞控制和接收方对发送方的流量控制一起考虑，那么很显然，发送方的窗口的上限值应当取为接收方窗口 rwnd 和拥塞窗口 cwnd 这两个变量中较小的一个，也就是说:  

发送方窗口的上限值 =Min [rwnd， cwnd]  

即rwnd 和 cwnd 中数值较小的一个，控制了发送方发送数据的速率。  

# 总结

- 运输层提供应用进程间的逻辑通信，也就是说，运输层之间的通信并不是真正在两个运输层之间直接传送数据。运输层向应用层屏蔽了下面网络的细节(如网络拓扑、所采用的路由选择协议等)，它使应用进程看见的就是好像在两个运输层实体之间有一条端到端的逻辑通信信道。  

- 网络层为主机之间提供逻辑通信，而运输层为应用进程之间提供端到端的逻辑通信。
- 运输层有两个主要的协议: TCP 和 UDP 。它们都有复用和分用，以及检错的功能。当运输层采用面向连接的 TCP 协议时，尽管下面的网络是不可靠的(只提供尽最大努力服务)，但这种逻辑通信信道就相当于一条全双工通信的可靠信道。当运输层采用无连接的 UDP 协议时，这种逻辑通信信道仍然是一条不可靠信道。  
- 运输层用一个 16 位端口号来标志一个端口。端口号只具有本地意义，它只是为了标志本计算机应用层中的各个进程在和运输层交互时的层间接口。在互联网的不同计算机中，相同的端口号是没有关联的。  
- 两台计算机中的进程要互相通信，不仅要知道对方的 IP 地址(为了找到对方的计算机)，而且还要知道对方的端口号(为了找到对方计算机中的应用进程)。  
- 运输层的端口号分为服务器端使用的端口号 (0 ~ 1023 指派给熟知端口， 1024 ~49151 是登记端口号〉和客户端暂时使用的端口号 (49152 ~ 65535) 。  
- TCP 的主要特点是: (1)面向连接; (2) 每一条 TCP 连接只能是点对点的(一对一); (3) 提供可靠交付的服务; (4) 提供全双工通信; (5) 面向字节流。  
- UDP 的主要特点是: (1) 无连接; (2) 尽最大努力交付; (3) 面向报文; (4) 无拥塞控制; (5) 支持一对一、一对多、多对一和多对多的交互通信; (6) 首部开销小(只有四个字段:源端口、目的端口、长度、检验和〉。  
- TCP 用主机的 E 地址加上主机上的端口号作为 TCP 连接的端点。这样的端点就叫做套接宇 (socket) 或插口。套接字用 (IP 地址 z 端口号)来表示。  
- 停止等待协议能够在不可靠的传输网络上实现可靠的通信。每发送完一个分组就停止发送，等待对方的确认。在收到确认后再发送下一个分组。分组需要进行编号。  
- 超时重传是指只要超过了一段时间仍然没有收到确认，就重传前面发送过的分组(认为刚才发送的分组丢失了)。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为自动重传请求 ARQ 
- 在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。
- 连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组都可连续发送出去，而不需要等待对方的确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都己正确收到了。
- TCP 报文段首部的前 20 个字节是固定的，后面有 4N 字节是根据需要而增加的选项 (N 是整数)。在一个 TCP 连接中传送的字节流中的每一个宇节都按顺序编号。首部中的序号宇段值则指的是本报文段所发送的数据的第一个字节的序号。        
- TCP 首部中的确认号是期望收到对方下一个报文段的第一个数据字节的序号。若确认号为 N， 则表明 z 到序号 N-l 为止的所有数据都己正确收到。  
- TCP 首部中的窗口宇段指出了现在允许对方发送的数据量。窗口值是经常在动态变化着的。
- TCP 使用滑动窗口机制。发送窗口里面的序号表示允许发送的序号。发送窗口后沿的后面部分表示己发送且己收到了确认，而发送窗口前沿的前面部分表示不允许发送。发送窗口后沿的变化情况有两种可能，即不动(没有收到新的确认〉和前移(收到了新的确认〉。发送窗口前沿通常是不断向前移动的。    

- 流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。  
- 在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫做拥塞。拥塞控制就是防止过多的数据注入到网络  中，这样可以使网络中的路由器或链路不致过载。  
- 流量控制是一个端到端的问题，是接收端抑制发送端发送数据的速率，以便使接收端来得及接收。拥塞控制是一个全局性的过程，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。  

- 为了进行拥塞控制， TCP 的发送方要维持一个拥塞窗口 cwnd 的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接收窗口中较小的一个。  

- TCP 的拥塞控制采用了四种算法，即慢开始、拥塞避免、快重传和快恢复。在网络层，也可以使路由器采用适当的分组丢弃策略(如主动队列管理 AQM) ，以减少网络拥塞的发生。  

- 运输连接有三个阶段，即  连接建立、数据传送和连接释放。  
- 主动发起 TCP 连接建立的应用进程叫做客户，而被动等待连接建立的应用进程叫做服务器。 TCP 的连接建立采用三报文握手机制。服务器要确认客户的连接请求，然后客户要对服务器的确认进行确认。  

- TCP 的连接释放采用四报文握手机制。任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后就进入半关闭状态。当另一方也没有数据再发送时，则发送连接释放通知，对方确认后就完全关闭了 TCP 连接。  